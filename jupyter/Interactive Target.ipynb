{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "The first block is mandatory, the second and the third can be run on demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUILDPLATFORM = 'stm32f4discovery'\n",
    "BUILDPLATFORM = 'cw308t-stm32f415'\n",
    "#BUILDPLATFORM = 'cw308t-stm32f3'\n",
    "lvl = \"l1\"\n",
    "m4f = True # implementation switch, either use m4f or mupq implementation\n",
    "# for m4f only levels 1 and 3 are implemented\n",
    "\n",
    "%run \"Setup_Disco_or_CWLITE.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this script cleans before building, so if one already built the firmware or is not sure about it, run it via terminal without `make clean`\n",
    "%run \"Build_Firmware.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target `mps2-an386` is not implemented in such a comfortable way as the other targets.\n",
    "\n",
    "First the target has to be started with `qemu-system-arm -M mps2-an386 -nographic -serial pty -semihosting -kernel <path_to_firmware_file>`, where the firmware path could be, e.g. `elf/mupq_crypto_kem_bikel11_opt_fi.elf`, if called from the pqm4 folder. This creates a pseudo terminal, bound to a file, which can be used as serial interface. This is usually located in `/dev/pts/`, the exact name is prompted and the variable `i` in the next block has to be set accordingly.\n",
    "If `i` is set the next block can be used to setup the Communication_Target object to comfortably interact with the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import serial\n",
    "import sys\n",
    "\n",
    "new_path = '../scripts/'\n",
    "\n",
    "if new_path not in sys.path:\n",
    "    sys.path.append(new_path)\n",
    "import target_com as com\n",
    "\n",
    "lvl = 'l11'\n",
    "i = ?\n",
    "\n",
    "target = serial.Serial(f\"/dev/pts/{i}\", 38400)\n",
    "t_com = com.Communication_Target(target, lvl)\n",
    "\n",
    "def reboot_flush():\n",
    "    # first use `system_reset` in qemu console\n",
    "    target.read_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "If firmware needs to be flashed run next block, otherwise skip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kat_bike as kat\n",
    "ff = f\"{'' if m4f else 'mupq_'}crypto_kem_bike{lvl}_{'m4f' if m4f else 'opt'}_fi\"\n",
    "%run \"Flash_Disco_CWLITE.ipynb\"\n",
    "\n",
    "reboot_flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Communication with the target\n",
    "\n",
    "Next blocks can be used to trigger specific operations or read data from target's memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reboot_flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_com.reset_prng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_com.keygen_async()\n",
    "t_com.check_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(20):\n",
    "\tt_com.encaps()\n",
    "\tt_com.decaps()\n",
    "\tprint(t_com.c_ss().hex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_com.encaps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_com.decaps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(t_com.r_ss().hex())\n",
    "print(t_com.r_ss_dec().hex())\n",
    "print(t_com.r_pk().hex())\n",
    "print(t_com.r_sk().hex())\n",
    "print(t_com.r_sk_mupq().hex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Generate correct keys\n",
    "\n",
    "Use key data from a KAT to verify communication and computation of weight index list which is required by mupq implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kat_bike as kat\n",
    "\n",
    "ref_kat = kat.read_rsp(lvl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bike_key as conv\n",
    "\n",
    "# chose which KAT to use\n",
    "cnt = 5\n",
    "pk = ref_kat[cnt].pk\n",
    "sk = ref_kat[cnt].sk\n",
    "ct = ref_kat[cnt].ct\n",
    "ss = ref_kat[cnt].ss\n",
    "\n",
    "key = conv.BIKE_key(sk, lvl)\n",
    "key.pk = pk\n",
    "\n",
    "# write keys and ciphertext to board\n",
    "t_com.w_pk(pk)\n",
    "t_com.w_ct(ct)\n",
    "t_com.w_sk(key.mupq_key)\n",
    "\n",
    "# test decapsulation\n",
    "t_com.decaps()\n",
    "if t_com.r_ss_dec() == ss:\n",
    "\tprint(\"decapsulation on board returned same shared secret as reference implementation\\nseems like everything is setup correctly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Capture Power Traces\n",
    "\n",
    "in the following we are going to capture power traces for the different subroutines of the kem. This works only for `CWLITE` and not for `discovery board`, because `discovery board` has hardware rng and no prng in pqm4 implemented, while `CWLITE` has only software prng and no hardware rng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "\n",
    "# if the triggers are set/unset within a loop it might make sense to use the async routines\n",
    "routines = [t_com.keygen, t_com.encaps, t_com.decaps_async]\n",
    "traces = dict()\n",
    "avg_traces = dict()\n",
    "Segments = list()\n",
    "cycles = dict()\n",
    "\n",
    "# set trace length to maximum\n",
    "scope.adc.samples = 24400\n",
    "\n",
    "###########\n",
    "# following values can be adjusted\n",
    "###########\n",
    "scope.adc.decimate = 50 # adjust trace resolution\n",
    "Traces = 20 # amount of separate traces per routine\n",
    "seed = 0 # prng will be regenerated seed times\n",
    "\n",
    "\n",
    "# determine capture values\n",
    "for routine in routines:\n",
    "    traces[routine] = list()\n",
    "    cycles[routine] = list()\n",
    "    scope.arm()\n",
    "    routine()\n",
    "    scope.capture()\n",
    "    if \"async\" in routine.__name__:\n",
    "        t_com.check_done()\n",
    "    \n",
    "    # calculate segments to capture for routine\n",
    "    # every segment is of length scope.adc.samples\n",
    "    s = math.ceil(scope.adc.trig_count*1.1 /scope.adc.samples/scope.adc.decimate)\n",
    "    Segments.append(s)\n",
    "\n",
    "    print(\"for routine {}\".format(routine.__name__))\n",
    "    print(\"which takes about {} clock cycles\".format(scope.adc.trig_count))\n",
    "    print(\"we will take {} segments for {} traces taking every {}th datum\".format(s, Traces, scope.adc.decimate))\n",
    "\n",
    "print()\n",
    "\n",
    "# not interested in ...\n",
    "# to avoid capturing traces for a specific routine \n",
    "# one can set the maximum segments to capture for this routine to 0\n",
    "#Segments[0] = 0\n",
    "#Segments[1] = 0\n",
    "#Segments[2] = 0\n",
    "\n",
    "for s in range(np.max(Segments)):\n",
    "    print(\"start capturing segment {}\".format(s))\n",
    "    # set cycles to wait after trigger event before capturing trace\n",
    "    scope.adc.offset = scope.adc.samples * s\n",
    "    #reset pseudo random number generator\n",
    "    t_com.reset_prng()\n",
    "    for i in range(seed):\n",
    "        t_com.regen_prng()\n",
    "    \n",
    "    for t in range(Traces):\n",
    "        # to get different ct and keys for encaps and decaps \n",
    "        # we take samples from consecutive runs of every routine\n",
    "        for routine, s_end in zip(routines, Segments):\n",
    "            # we do not need to run decaps when we already captured enough traces\n",
    "            # because no other routine depends on its output\n",
    "            if routine.__name__ == \"decaps\" and s > s_end: continue\n",
    "\n",
    "            scope.arm()\n",
    "            if not routine() and not \"async\" in routine.__name__: \n",
    "                print(\"out of sync\")\n",
    "                exit()\n",
    "            ret = scope.capture()\n",
    "            if \"async\" in routine.__name__:\n",
    "                t_com.check_done()\n",
    "            \n",
    "            if s == 0: \n",
    "                # apend new trace\n",
    "                traces[routine].append(scope.get_last_trace())\n",
    "            elif s < s_end:\n",
    "                # extend existing trace but discard idle samples\n",
    "                traces[routine][t] = np.concatenate((traces[routine][t], scope.get_last_trace()), axis=0)\n",
    "            \n",
    "            # save the number of cycles the trigger was high\n",
    "            cycles[routine].append(scope.adc.trig_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show the cycles the trigger was high during capturing one can run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in routines:\n",
    "\tprint(\"for {} the trigger was high for ... cycles\".format(r.__name__))\n",
    "\tprint(\" {} maximum\".format(np.max(cycles[r])))\n",
    "\tprint(\" {} average\".format(np.average(cycles[r])))\n",
    "\tprint(\" {} minimum\".format(np.min(cycles[r])))\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load Traces\n",
    "The next block will store the currently captured power traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shelve\n",
    "data = shelve.open(\"../traces/power\", writeback = True)\n",
    "\n",
    "try:\n",
    "\tfor r in routines:\n",
    "\t\tkey = \"raw_reenc.sparse_{}_{}\".format(r.__name__, scope.adc.decimate)\n",
    "\t\tdata[key] = traces[r]\n",
    "finally:\n",
    "\tdata.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and here we can load them again.\n",
    "\n",
    "The first block will show the keys available in the `shelve`, the second block's intention is to load one of the raw traces (several traces per key) and calculate the average and the standard deviation of those traces and make them ready for plotting in the `trace` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show saved keys\n",
    "import shelve\n",
    "\n",
    "data = shelve.open(\"../traces/power\")\n",
    "for k in data.keys():\n",
    "\tprint(k)\n",
    "data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shelve\n",
    "import numpy as np\n",
    "\n",
    "alg = \"keygen\"\n",
    "\n",
    "trace = list()\n",
    "data = shelve.open(\"../traces/power\")\n",
    "try:\n",
    "\t# choose a key from the previous cell's output\n",
    "\tkey = \"raw_{}_50\".format(alg)\n",
    "\ttrace.append(data[key])\n",
    "finally:\n",
    "\tdata.close()\n",
    "\n",
    "trace.append(np.average(trace[0], axis=0))\n",
    "trace.append(np.std(trace[0], axis=0))\n",
    "trace.pop(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "This will visualize the traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if one wants to process the last captured traces run this block\n",
    "# if the traces just were loaded the variables are already set correct so skip this block and use the next one.\n",
    "\n",
    "# set the index of the routine you are interested in\n",
    "r = routines[0]\n",
    "\n",
    "trace = list()\n",
    "trace.append(np.average(traces[r], axis=0)[:14000])\n",
    "trace.append(np.std(traces[r], axis=0)[:14000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "plt.figure()\n",
    "for t in trace:\n",
    "\tplt.plot(t)\n",
    "plt.xlabel(\"Clock Cycles\")\n",
    "plt.ylabel(\"Voltage\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faulty Keys\n",
    "\n",
    "Before we try to intercept at key generation with fault injection to generate faulty keys, we first calculate faulty keys on the host and see if and how the target board processes them.\n",
    "\n",
    "For every secret key there is only one public key, so if we alter a secret key we have to calculate the corresponding public key and can't just use the same public key.\n",
    "$$ sk = (h_0, h_1, \\sigma ) $$\n",
    "$$ pk = h_1 \\cdot h_0^{-1} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Host Public Key Generation\n",
    "The next code block takes a key pair from a KAT file, calculates the public key from the given secret key and compares both public keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"new_path\" not in dir():\n",
    "    global new_path\n",
    "    new_path = '../scripts/'\n",
    "\n",
    "if new_path not in sys.path:\n",
    "    sys.path.append(new_path)\n",
    "\n",
    "import bike_key as bk\n",
    "import kat_bike as kat\n",
    "\n",
    "# chose key pair of KAT file and BIKE level\n",
    "k = 60\n",
    "lvl = \"l11\"\n",
    "\n",
    "rsp = kat.read_rsp(lvl)\n",
    "key = bk.BIKE_key(rsp[k].sk, lvl)\n",
    "\n",
    "print(rsp[k].pk.hex())\n",
    "print(key.pk.hex())\n",
    "if key.pk == rsp[k].pk:\n",
    "    print(\"The calculated key matches the one from the file!\\nSUCCESS\")\n",
    "else:\n",
    "    print(\"The calculated key does NOT match the one from the file!\\nERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use host generated (Faulty) Keys\n",
    "To determine which kind of faults take which effect we can generate faulty keys of various kinds on the host and pass them to the target. The aim is to achieve a DFR of about 50%. With the following blocks we can determine the DFR for different weights and kinds of faulty keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init target\n",
    "BUILDPLATFORM = 'cw308t-stm32f3'\n",
    "BUILDPLATFORM = 'stm32f4discovery'\n",
    "lvl = \"l11\"\n",
    "%run \"Setup_Disco_or_CWLITE.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example faulty key generation and enc/dec on target\n",
    "if \"new_path\" not in dir():\n",
    "    global new_path\n",
    "    new_path = '../scripts/'\n",
    "\n",
    "if new_path not in sys.path:\n",
    "    sys.path.append(new_path)\n",
    "import bike_key as bk\n",
    "\n",
    "fm = bk.FaultMode(bk.FK_Kind.TWO, bk.PK_Kind.SK, bk.WL_Kind.MISMATCH, bk.Fault.SK)\n",
    "key = bk.faulty_key_fm(t_com.lvl.d*0.5, fm, lvl)\n",
    "\n",
    "t_com.w_sk(key.mupq_key)\n",
    "t_com.w_pk(key.pk)\n",
    "\n",
    "t_com.encaps()\n",
    "t_com.decaps()\n",
    "print(t_com.c_ss().hex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trigger enc/dec and read result\n",
    "for _ in range(5):\n",
    "\tt_com.encaps()\t\n",
    "\tt_com.decaps()\n",
    "\tprint(t_com.c_ss().hex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if key analysis works fine\n",
    "if \"new_path\" not in dir():\n",
    "    global new_path\n",
    "    new_path = '../scripts/'\n",
    "\n",
    "if new_path not in sys.path:\n",
    "    sys.path.append(new_path)\n",
    "import bike_key as bk\n",
    "\n",
    "for i,fm in enumerate(bk.get_valid_faultmodes()):\n",
    "\tfor d in [int(t_com.lvl.d*0.6), int(t_com.lvl.d*1.4)]:\n",
    "\t\tkey = bk.faulty_key_fm(d, fm, lvl)\n",
    "\t\tf = bk.analyze_key(key.mupq_key, t_com.lvl)\n",
    "\t\tcheck = f[0] == fm\n",
    "\t\tif not check:\n",
    "\t\t\tprint(f\"in round {i},\\nfor weight {d} and \\n{fm}\\n\\n{f[0]}\\n{f[1]}, {f[2]} and {f[3]} was recognized\\n\\n\")\n",
    "\n",
    "print(f\"if there was no output, every of the {len(bk.get_valid_faultmodes())} different fault modes was successfully recognized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the previous code blocks one can check if the base methods for the following steps work fine.\n",
    "\n",
    "### Decoding Failure Rate DFR\n",
    "The following block allows to run through all valid FaultModes (or a subset of them), generate faulty keys according to them in a range of weights and trigger multiple encapsulations and decapsulations. If it was successful or not will be stored. The blocks afterwards can save the results via shelve, calculate the DFR from the results and plot the DFR for every FaultMode separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture enc/dec results for multiple fault modes and weights\n",
    "import bike_key as bk\n",
    "keys = 12\n",
    "runs = 30\n",
    "\n",
    "D = t_com.lvl.d\n",
    "dmin, dmax = int(D * 0.45), int(D * 2)\n",
    "\n",
    "fms = bk.get_valid_faultmodes() #wl_kind=[bk.WL_Kind.MISMATCH])\n",
    "# wlk = [bk.WL_Kind.MULTI] #, bk.WL_Kind.UNSET, bk.WL_Kind.MISMATCH]\n",
    "# pkk = [bk.PK_Kind.SK]\n",
    "# fms = [bk.FaultMode(bk.FK_Kind.TWOa,pk,wl,bk.Fault.SK) for pk in pkk for wl in wlk]\n",
    "\n",
    "results = dict()\n",
    "for i, fm in enumerate(fms):\n",
    "\tprint(f\"start with fault mode {i+1} of {len(fms)}\")\n",
    "\tresults[fm] = dict()\n",
    "\tfor d in range(dmin, dmax):\n",
    "\t\tresults[fm][d] = list()\n",
    "\t\tfor _ in range(keys):\n",
    "\t\t\tkey = bk.faulty_key_fm(d, fm.new(), lvl)\n",
    "\t\t\tt_com.w_sk(key.mupq_key)\n",
    "\t\t\tt_com.w_pk(key.pk)\n",
    "\t\t\tfor _ in range(runs):\n",
    "\t\t\t\tt_com.encaps()\t\n",
    "\t\t\t\tt_com.decaps()\n",
    "\t\t\t\tresults[fm][d].append(t_com.c_ss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save enc/dec data\n",
    "import shelve\n",
    "data = shelve.open(\"../traces/power\", writeback = True)\n",
    "\n",
    "try:\n",
    "\tfor i,r in enumerate(results):\n",
    "\t\tkey = f\"faultm{i}\"\n",
    "\t\tdata[key] = results[r]\n",
    "finally:\n",
    "\tdata.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dec/enc data\n",
    "import shelve\n",
    "data = shelve.open(\"../traces/power\")\n",
    "\n",
    "results = dict()\n",
    "fms = bk.get_valid_faultmodes()\n",
    "try:\n",
    "\tfor i, fm in enumerate(fms):\n",
    "\t\tresults[fm] = data[f\"faultm{i}\"]\n",
    "finally:\n",
    "\tdata.close()\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute decoding failure rate\n",
    "dfr = dict()\n",
    "for i,fm in enumerate(results):\n",
    "\tdfr[i] = list()\n",
    "\tfor d_list in results[fm].values():\n",
    "\t\tdfr[i].append(1-(d_list.count(b'\\x00') /len(d_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,fm in enumerate(fms):\n",
    "\tdfr_tuples = [(j+dmin, d) for j,d in enumerate(dfr[i])]\n",
    "\tprint(fm)\n",
    "\tfor j,d in dfr_tuples: print(j, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot dfr and print fault mode\n",
    "import matplotlib.pylab as plt\n",
    "# D = t_com.lvl.d\n",
    "# dmin, dmax = int(D * 0.3), int(D * 1.8)\n",
    "\n",
    "for i,fm in enumerate(fms):\n",
    "\tplt.xlim(dmin,dmax)\n",
    "\tplt.xlabel(\"Row Weight D\")\n",
    "\tplt.ylabel(\"Decoding Failure Rate DFR\")\n",
    "\tplt.plot([0 for _ in range(dmin)] + dfr[i])\n",
    "\tprint(fm)\n",
    "\tplt.savefig(f\"{fm.SK},{fm.PK},{fm.WK},{fm.Fault}.png\")\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.dis()\n",
    "scope.dis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
